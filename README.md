# RecallAI ğŸ§ 

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org)
[![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)](https://flask.palletsprojects.com)
[![Groq](https://img.shields.io/badge/Groq-LLM-orange.svg)](https://groq.com)
[![FAISS](https://img.shields.io/badge/FAISS-Vector%20Search-red.svg)](https://github.com/facebookresearch/faiss)
[![LangChain](https://img.shields.io/badge/LangChain-0.1.0-purple.svg)](https://python.langchain.com)

An intelligent document and YouTube video Q&A system powered by Groq LLM and semantic search. Upload documents or YouTube videos and ask questions to get accurate, contextual answers.

## ğŸ— Architecture

```plaintext
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client     â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Flask API  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â–¼           â–¼           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚Document  â”‚ â”‚ YouTube â”‚ â”‚  Text  â”‚
            â”‚Processor â”‚ â”‚  API    â”‚ â”‚Splitterâ”‚
            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                 â”‚           â”‚          â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Text Chunks    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                      â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   Sentence   â”‚      â”‚    Vector     â”‚
      â”‚ Transformer  â”‚      â”‚    Store      â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Groq LLM     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Response     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ğŸ›  Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| ğŸŒ API Framework | Flask | RESTful API endpoints |
| ğŸ§  LLM Engine | Groq | AI reasoning & responses |
| ğŸ“Š Vector Store | FAISS | Semantic search |
| ğŸ”¤ Embeddings | Sentence Transformers | Text vectorization |
| ğŸ“ Text Processing | LangChain | Document chunking |
| ğŸ“º Video Processing | YouTube Transcript API | Caption extraction |
| ğŸ—„ï¸ Document Processing | PyMuPDF & python-docx | File parsing |
| ğŸ”„ Process Management | Gunicorn | Production server |
| ğŸ” Memory Management | psutil | Resource monitoring |

## ğŸŒŸ Features

- **Document Processing** ğŸ“„
  - PDF and DOCX support
  - Automatic text extraction
  - Smart chunking and embedding
  - Memory-efficient processing

- **YouTube Integration** ğŸ¥
  - Transcript extraction
  - Automatic caption processing
  - Full video context understanding

- **Intelligent Q&A** ğŸ’¡
  - Context-aware responses
  - Multi-step reasoning:
    1. Question clarification
    2. Relevant context retrieval
    3. Draft answer generation
    4. Answer refinement

- **Performance Optimized** âš¡
  - Memory-efficient processing
  - Automatic resource management
  - Configurable chunk sizes
  - Regular cleanup cycles

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Groq API key
- Virtual environment

### Installation

1. Clone the repository
```bash
git clone https://github.com/santanu2402/RecallAI-Backend.git
cd RecallAI
```

2. Create and activate virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

4. Set up environment variables
```bash
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
```

5. Run the application
```bash
python app.py
```

## ğŸ”§ Configuration

| Environment Variable | Description | Default |
|---------------------|-------------|---------|
| GROQ_API_KEY | Your Groq API key | Required |
| UPLOAD_DIR | Directory for file uploads | /tmp |
| MAX_UPLOADS | Maximum concurrent uploads | 3 |
| MAX_FILE_SIZE | Maximum file size in bytes | 5MB |
| CHUNK_SIZE | Text chunk size | 400 |
| CHUNK_OVERLAP | Chunk overlap size | 40 |
| CLEANUP_INTERVAL | Cleanup interval in seconds | 900 |

## ğŸ“¡ API Endpoints

### File Upload
```http
POST /upload/file
Content-Type: multipart/form-data

file: <file>
```

### YouTube Upload
```http
POST /upload/youtube
Content-Type: application/json

{
    "url": "https://www.youtube.com/watch?v=..."
}
```

### Ask Question
```http
POST /ask
Content-Type: application/json

{
    "question": "Your question here",
    "upload_no": "upload_id"
}
```

### Health Check
```http
GET /health
```

## ğŸ” Example Usage

```python
import requests

# Upload a PDF
files = {'file': open('document.pdf', 'rb')}
upload_response = requests.post('http://localhost:5000/upload/file', files=files)
upload_id = upload_response.json()['upload_no']

# Ask a question
question = {
    'question': 'What are the main points discussed?',
    'upload_no': upload_id
}
answer = requests.post('http://localhost:5000/ask', json=question)
print(answer.json()['answer'])
```

## ğŸš¢ Deployment

### Local Development
```bash
python app.py
```

### Production (Gunicorn)
```bash
gunicorn -c gunicorn.conf.py "app:create_app()"
```

### GCP e2-micro
Follow the detailed guide in [GCP_E2_DEPLOY.md](GCP_E2_DEPLOY.md)

## ğŸ” Security Notes

- Set appropriate file size limits
- Configure CORS settings
- Use HTTPS in production
- Secure API key management
- Regular cleanup of uploaded files

## ğŸ“Š Monitoring

- Memory usage tracking
- Resource utilization alerts
- Operation logging
- Error tracking
- Performance metrics

## ğŸ›  Development

### Running Tests
```bash
python -m unittest test_app.py -v
```

### Code Style
```bash
pip install flake8
flake8 app.py
```

## ğŸ“ Technical Details

- **Embedding Model**: all-MiniLM-L6-v2 (384 dimensions)
- **LLM**: Groq llama3-70b-8192
- **Vector Store**: FAISS
- **Text Processing**: LangChain
- **Memory Management**: Automatic cleanup and monitoring

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. Commit your changes
   ```bash
   git commit -m 'Add some AmazingFeature'
   ```
4. Push to the branch
   ```bash
   git push origin feature/AmazingFeature
   ```
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Groq](https://groq.com) for the LLM API
- [Sentence Transformers](https://www.sbert.net) for embeddings
- [FAISS](https://github.com/facebookresearch/faiss) for vector search
- [LangChain](https://python.langchain.com) for text processing
- [Flask](https://flask.palletsprojects.com) for the web framework
